{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Channel Coding Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append('../')\n",
    "from data_utils.gen_channel_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the list of configs to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    \"awgn_narrow\",\n",
    "    \"awgn_mid\",\n",
    "    \"awgn_mid_higher\",\n",
    "    \"awgn_mid_lower\",\n",
    "    \"awgn_wide\",\n",
    "    \"bursty_hard_narrow\",\n",
    "    \"bursty_hard_mid\",\n",
    "    \"bursty_hard_mid_high\",\n",
    "    \"bursty_hard_mid_low\",\n",
    "    \"bursty_hard_wide\",\n",
    "    \"mem_hard_narrow\",\n",
    "    \"mem_hard_mid\",\n",
    "    \"mem_hard_mid_higher\",\n",
    "    \"mem_hard_mid_lower\",\n",
    "    \"mem_hard_wide\",\n",
    "    \"mp_hard_narrow\",\n",
    "    \"mp_hard_mid\",\n",
    "    \"mp_hard_mid_higher\",\n",
    "    \"mp_hard_mid_lower\",\n",
    "    \"mp_hard_wide\",\n",
    "    \"mix_hard_narrow\",\n",
    "    \"mix_hard_wide\"\n",
    "]\n",
    "\n",
    "configs_dir = '../configs/set_nd_15ts_5cls/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_arrangement(input_metrics, num_copies=1):\n",
    "    org_metrics = []\n",
    "\n",
    "    for noise_type, snr_param in input_metrics.items():\n",
    "        if len(snr_param[\"snr\"]) == 3:\n",
    "            snr_low, snr_hi, snr_stp = snr_param[\"snr\"]\n",
    "            snr_list = np.arange(snr_low, snr_hi, snr_stp)\n",
    "        else:\n",
    "            snr_list = snr_param[\"snr\"]\n",
    "        if not snr_param[\"param\"]:\n",
    "            for snr in snr_list:\n",
    "                for j in range(num_copies):\n",
    "                    org_metrics.append(\n",
    "                        {\"noise_type\": noise_type, \"snr\": float(snr)})\n",
    "            continue\n",
    "\n",
    "        para_len = len(snr_param[\"param\"][np.random.choice(\n",
    "            list(snr_param[\"param\"].keys()), size=1, replace=False)[0]])\n",
    "\n",
    "        for snr in snr_list:\n",
    "            for i in range(para_len):\n",
    "                met_dict = {\"noise_type\": noise_type, \"snr\": float(snr)}\n",
    "                for para in snr_param[\"param\"].keys():\n",
    "                    if noise_type == \"t\" and para == \"vv\":\n",
    "                        assert snr_param[\"param\"][para][i] >= 2, \"T channel requires parameter vv to be no less than 2\"\n",
    "                    met_dict[para] = snr_param[\"param\"][para][i]\n",
    "\n",
    "                for j in range(num_copies):\n",
    "                    org_metrics.append(met_dict)\n",
    "                met_dict = {}\n",
    "    return org_metrics\n",
    "\n",
    "def sample_a_metric(seed, train_range_dict, debug=False):\n",
    "    \"\"\"\n",
    "    Given ranges of each channel type sample a criteria for data generation\n",
    "    \"\"\"\n",
    "    if debug:\n",
    "        print(\"sample a metric with seed \", seed, \" dict: \",\n",
    "                train_range_dict, \" noise types \", list(train_range_dict.keys()))\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    # channel_type_len = len(train_trange_dict)\n",
    "    selected_channel = rng.choice(list(train_range_dict.keys()), size=1)[0]\n",
    "    selected_channel_range = train_range_dict[selected_channel]\n",
    "    if debug:\n",
    "        print(\"selected type \", selected_channel,\n",
    "                \" range \", selected_channel_range)\n",
    "\n",
    "    met_dict = {\"noise_type\": selected_channel}\n",
    "\n",
    "    for param, range_list in selected_channel_range.items():\n",
    "        min_, max_ = range_list[0], range_list[1]\n",
    "        val = np.random.uniform(min_, max_)\n",
    "        met_dict[param] = val\n",
    "    if debug:\n",
    "        print(\"RETURNING sampled dict \", met_dict)\n",
    "    return met_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# create training dataset\n",
    "num_noise_setups = 200\n",
    "num_classes_per_noise_setup = 1000\n",
    "num_examples_per_class = 50\n",
    "start = time.time()\n",
    "\n",
    "# take one config at a time\n",
    "for i, config in enumerate(configs):\n",
    "    print('Config ' + str(i + 1) + ': ' + config)\n",
    "\n",
    "    with open(configs_dir + config + '.json', 'r') as f:\n",
    "        params = json.load(f)\n",
    "    train_range_dict = params['train_range_dict']\n",
    "    image_height = 10\n",
    "\n",
    "    images_all = []\n",
    "    labels_all = []\n",
    "    batch_criteria_all = []\n",
    "\n",
    "    for noise_setup in range(num_noise_setups):\n",
    "        seed = random.randint(1, 999999)\n",
    "        rng = np.random.RandomState(seed)\n",
    "\n",
    "        images = []\n",
    "        labels = []\n",
    "        batch_criteria = sample_a_metric(seed=rng.randint(1, 999999), train_range_dict=train_range_dict)\n",
    "\n",
    "        for i in range(num_classes_per_noise_setup):\n",
    "            x_class_data, true_msgs = generate_viterbi_batch(batch_size=num_examples_per_class,\n",
    "                                                             block_len=image_height,\n",
    "                                                             batch_criteria=batch_criteria,\n",
    "                                                             seed=rng.randint(1, 999999))\n",
    "            x_class_data = np.array(x_class_data, dtype=np.float32)\n",
    "            images.append(x_class_data)\n",
    "            labels.append(true_msgs)\n",
    "\n",
    "        images = np.array(images, dtype=np.float32)\n",
    "        labels = np.array(labels, dtype=np.float32)\n",
    "\n",
    "        images_all.append(images)\n",
    "        labels_all.append(labels)\n",
    "        batch_criteria_all.append(batch_criteria)\n",
    "\n",
    "    images_all = np.array(images_all, dtype=np.float32)\n",
    "    labels_all = np.array(labels_all, dtype=np.float32)\n",
    "\n",
    "#     diff_support_query_v2\n",
    "#     np.savez('../datasets/tmp/train/' + config + '_data.npz', train_images=images_all, train_labels=labels_all)\n",
    "#     with open('../datasets/tmp/train/' + config + '_criteria.json', 'w') as f:\n",
    "#         json.dump({'criteria': batch_criteria_all}, f)\n",
    "\n",
    "    print('Elapsed time: {:.1f}'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the testing set - in a similar way as the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# create test dataset\n",
    "\n",
    "# we can get any config, the dataset should not depend on it\n",
    "config = configs[0]\n",
    "\n",
    "with open(configs_dir + config + '.json', 'r') as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "\n",
    "batch_arrange = get_metric_arrangement(params['val_metrics'], num_copies=1)\n",
    "num_noise_setups = len(batch_arrange)\n",
    "num_classes_per_noise_setup = 50\n",
    "num_examples_per_class = 50\n",
    "\n",
    "images_all_test = []\n",
    "labels_all_test = []\n",
    "batch_criteria_all_test = []\n",
    "\n",
    "for noise_setup in range(num_noise_setups):\n",
    "    seed = random.randint(1, 999999)\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    batch_criteria = batch_arrange[noise_setup]\n",
    "\n",
    "    for i in range(num_classes_per_noise_setup):\n",
    "        x_class_data, true_msgs = generate_viterbi_batch(batch_size=num_examples_per_class,\n",
    "                                                         block_len=image_height,\n",
    "                                                         batch_criteria=batch_criteria,\n",
    "                                                         seed=rng.randint(1, 999999))\n",
    "        x_class_data = np.array(x_class_data, dtype=np.float32)\n",
    "        images.append(x_class_data)\n",
    "        labels.append(true_msgs)\n",
    "\n",
    "    images = np.array(images, dtype=np.float32)\n",
    "    labels = np.array(labels, dtype=np.float32)\n",
    "\n",
    "    images_all_test.append(images)\n",
    "    labels_all_test.append(labels)\n",
    "    batch_criteria_all_test.append(batch_criteria)\n",
    "\n",
    "images_all_test = np.array(images_all_test, dtype=np.float32)\n",
    "labels_all_test = np.array(labels_all_test, dtype=np.float32)\n",
    "\n",
    "# np.savez('../datasets/diff_support_query/test/' + 'test_data.npz', test_images=images_all_test, test_labels=labels_all_test)\n",
    "# with open('../datasets/diff_support_query/test/test_criteria.json', 'w') as f:\n",
    "#     json.dump({'criteria': batch_criteria_all_test}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bursty easy requires a different test set - create it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# create test dataset\n",
    "\n",
    "# we can get any config, the dataset should not depend on it\n",
    "config = configs[5]\n",
    "\n",
    "assert 'bursty_easy' in config\n",
    "\n",
    "with open(configs_dir + config + '.json', 'r') as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "image_height = params['image_height']\n",
    "batch_arrange = get_metric_arrangement(params['val_metrics'], num_copies=1)\n",
    "num_noise_setups = len(batch_arrange)\n",
    "num_classes_per_noise_setup = 50\n",
    "num_examples_per_class = 50\n",
    "\n",
    "images_all_test = []\n",
    "labels_all_test = []\n",
    "batch_criteria_all_test = []\n",
    "\n",
    "for noise_setup in range(num_noise_setups):\n",
    "    seed = random.randint(1, 999999)\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    batch_criteria = batch_arrange[noise_setup]\n",
    "\n",
    "    for i in range(num_classes_per_noise_setup):\n",
    "        x_class_data, true_msgs = generate_viterbi_batch(batch_size=num_examples_per_class,\n",
    "                                                         block_len=image_height,\n",
    "                                                         batch_criteria=batch_criteria,\n",
    "                                                         seed=rng.randint(1, 999999))\n",
    "        x_class_data = np.array(x_class_data, dtype=np.float32)\n",
    "        images.append(x_class_data)\n",
    "        labels.append(true_msgs)\n",
    "\n",
    "    images = np.array(images, dtype=np.float32)\n",
    "    labels = np.array(labels, dtype=np.float32)\n",
    "\n",
    "    images_all_test.append(images)\n",
    "    labels_all_test.append(labels)\n",
    "    batch_criteria_all_test.append(batch_criteria)\n",
    "\n",
    "images_all_test = np.array(images_all_test, dtype=np.float32)\n",
    "labels_all_test = np.array(labels_all_test, dtype=np.float32)\n",
    "\n",
    "# np.savez('../datasets/test/' + 'bursty_easy_test_data.npz', test_images=images_all_test, test_labels=labels_all_test)\n",
    "# with open('../datasets/test/bursty_easy_test_criteria.json', 'w') as f:\n",
    "#     json.dump({'criteria': batch_criteria_all_test}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if we can use the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../datasets/test/test_data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['test_images'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
